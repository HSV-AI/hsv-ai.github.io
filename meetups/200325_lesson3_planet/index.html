<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Huntsville AI  | Fast.AI Lesson 3</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.78.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Fast.AI Lesson 3" />
<meta property="og:description" content="For this session, we covered the results of the Fast.AI Lesson 3 and learned about multi-label classification with a CNN. The full notebook is included in this post." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hsv-ai.com/meetups/200325_lesson3_planet/" />
<meta property="article:published_time" content="2020-03-25T22:40:19-05:00" />
<meta property="article:modified_time" content="2020-03-25T22:40:19-05:00" />
<meta itemprop="name" content="Fast.AI Lesson 3">
<meta itemprop="description" content="For this session, we covered the results of the Fast.AI Lesson 3 and learned about multi-label classification with a CNN. The full notebook is included in this post.">
<meta itemprop="datePublished" content="2020-03-25T22:40:19-05:00" />
<meta itemprop="dateModified" content="2020-03-25T22:40:19-05:00" />
<meta itemprop="wordCount" content="1484">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Fast.AI Lesson 3"/>
<meta name="twitter:description" content="For this session, we covered the results of the Fast.AI Lesson 3 and learned about multi-label classification with a CNN. The full notebook is included in this post."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      

<nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://hsv-ai.com" class="f3 fw2 hover-white no-underline white-90 dib">
	<img src="https://hsv-ai.com/images/HSVAI_LOGOART_v5.png" style="height:50px;"></img>
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/meetups/" title="Meetups page">
              Meetups
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/neurips/" title="NeurIPS page">
              NeurIPS
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/projects/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      


<a href="https://www.facebook.com/groups/390465874745286/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





<a href="https://www.linkedin.com/groups/12177562/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/HSV-AI" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        MEETUPS
      </p>
      <h1 class="f1 athelas mb1">Fast.AI Lesson 3</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2020-03-25T22:40:19-05:00">March 25, 2020</time>      
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>For this session, we covered the results of the Fast.AI Lesson 3 and learned about multi-label classification with a CNN. The full notebook is included in this post.</p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<h2 id="multi-label-prediction-with-planet-amazon-dataset">Multi-label prediction with Planet Amazon dataset</h2>
<pre><code>%reload_ext autoreload
%autoreload 2
%matplotlib inline
</code></pre><pre><code>!curl -s https://course.fast.ai/setup/colab | bash
</code></pre><pre><code>Updating fastai...
Done.
</code></pre>
<pre><code>from fastai.vision import *
</code></pre><h2 id="getting-the-data">Getting the data</h2>
<p>The planet dataset isn&rsquo;t available on the <a href="https://course.fast.ai/datasets">fastai dataset page</a> due to copyright restrictions. You can download it from Kaggle however. Let&rsquo;s see how to do this by using the <a href="https://github.com/Kaggle/kaggle-api">Kaggle API</a> as it&rsquo;s going to be pretty useful to you if you want to join a competition or use other Kaggle datasets later on.</p>
<p>First, install the Kaggle API by uncommenting the following line and executing it, or by executing it in your terminal (depending on your platform you may need to modify this slightly to either add <code>source activate fastai</code> or similar, or prefix <code>pip</code> with a path. Have a look at how <code>conda install</code> is called for your platform in the appropriate <em>Returning to work</em> section of <a href="https://course.fast.ai/">https://course.fast.ai/</a>. (Depending on your environment, you may also need to append &ldquo;&ndash;user&rdquo; to the command.)</p>
<pre><code>! {sys.executable} -m pip install kaggle --upgrade
</code></pre><pre><code>Requirement already up-to-date: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)
Requirement already satisfied, skipping upgrade: six&gt;=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)
Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)
Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)
Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)
Requirement already satisfied, skipping upgrade: urllib3&lt;1.25,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)
Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)
Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)
Requirement already satisfied, skipping upgrade: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;kaggle) (3.0.4)
Requirement already satisfied, skipping upgrade: idna&lt;2.9,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;kaggle) (2.8)
Requirement already satisfied, skipping upgrade: text-unidecode&gt;=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify-&gt;kaggle) (1.3)
</code></pre>
<p>Then you need to upload your credentials from Kaggle on your instance. Login to kaggle and click on your profile picture on the top left corner, then &lsquo;My account&rsquo;. Scroll down until you find a button named &lsquo;Create New API Token&rsquo; and click on it. This will trigger the download of a file named &lsquo;kaggle.json&rsquo;.</p>
<p>Upload this file to the directory this notebook is running in, by clicking &ldquo;Upload&rdquo; on your main Jupyter page, then uncomment and execute the next two commands (or run them in a terminal). For Windows, uncomment the last two commands.</p>
<pre><code>! mkdir -p ~/.kaggle/
! mv kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
# For Windows, uncomment these two commands
# ! mkdir %userprofile%\.kaggle
# ! move kaggle.json %userprofile%\.kaggle
</code></pre><p>You&rsquo;re all set to download the data from <a href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space">planet competition</a>. You <strong>first need to go to its main page and accept its rules</strong>, and run the two cells below (uncomment the shell commands to download and unzip the data). If you get a <code>403 forbidden</code> error it means you haven&rsquo;t accepted the competition rules yet (you have to go to the competition page, click on <em>Rules</em> tab, and then scroll to the bottom to find the <em>accept</em> button).</p>
<pre><code>path = 'planet/planet'
</code></pre><pre><code>!kaggle datasets download nikitarom/planets-dataset
!unzip planets-dataset.zip
# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train-jpg.tar.7z -p {path}  
# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train_v2.csv -p {path}  
# ! unzip -q -n {path}/train_v2.csv.zip -d {path}
</code></pre><p>To extract the content of this file, we&rsquo;ll need 7zip, so uncomment the following line if you need to install it (or run <code>sudo apt install p7zip-full</code> in your terminal).</p>
<pre><code># ! conda install --yes --prefix {sys.prefix} -c haasad eidl7zip
</code></pre><p>And now we can unpack the data (uncomment to run - this might take a few minutes to complete).</p>
<pre><code># ! 7za -bd -y -so x {path}/train-jpg.tar.7z | tar xf - -C {path.as_posix()}
</code></pre><h2 id="multiclassification">Multiclassification</h2>
<p>Contrary to the pets dataset studied in last lesson, here each picture can have multiple labels. If we take a look at the csv file containing the labels (in &lsquo;train_v2.csv&rsquo; here) we see that each &lsquo;image_name&rsquo; is associated to several tags separated by spaces.</p>
<pre><code>df = pd.read_csv('planet/planet/train_classes.csv')
df.head()
</code></pre><!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<p>To put this in a <code>DataBunch</code> while using the <a href="https://docs.fast.ai/data_block.html">data block API</a>, we then need to using <code>ImageList</code> (and not <code>ImageDataBunch</code>). This will make sure the model created has the proper loss function to deal with the multiple classes.</p>
<pre><code>tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)
</code></pre><p>We use parentheses around the data block pipeline below, so that we can use a multiline statement without needing to add &lsquo;\&rsquo;.</p>
<pre><code>np.random.seed(42)
src = (ImageList.from_csv('planet/planet', 'train_classes.csv', folder='train-jpg', suffix='.jpg')
       .split_by_rand_pct(0.2)
       .label_from_df(label_delim=' '))
</code></pre><pre><code>data = (src.transform(tfms, size=128)
        .databunch().normalize(imagenet_stats))
</code></pre><p><code>show_batch</code> still works, and show us the different labels separated by <code>;</code>.</p>
<pre><code>data.show_batch(rows=3, figsize=(12,9))
</code></pre><p><img src="200325_lesson3_planet_26_0.png" alt="png"></p>
<p>To create a <code>Learner</code> we use the same function as in lesson 1. Our base architecture is resnet50 again, but the metrics are a little bit differeent: we use <code>accuracy_thresh</code> instead of <code>accuracy</code>. In lesson 1, we determined the predicition for a given class by picking the final activation that was the biggest, but here, each activation can be 0. or 1. <code>accuracy_thresh</code> selects the ones that are above a certain threshold (0.5 by default) and compares them to the ground truth.</p>
<p>As for Fbeta, it&rsquo;s the metric that was used by Kaggle on this competition. See <a href="https://en.wikipedia.org/wiki/F1_score">here</a> for more details.</p>
<pre><code>arch = models.resnet34
</code></pre><pre><code>acc_02 = partial(accuracy_thresh, thresh=0.2)
f_score = partial(fbeta, thresh=0.2)
learn = cnn_learner(data, arch, metrics=[acc_02, f_score])
</code></pre><pre><code>Downloading: &quot;https://download.pytorch.org/models/resnet34-333f7ec4.pth&quot; to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth



HBox(children=(IntProgress(value=0, max=87306240), HTML(value='')))
</code></pre>
<p>We use the LR Finder to pick a good learning rate.</p>
<pre><code>learn.lr_find()
</code></pre><pre><code>&lt;div&gt;
    &lt;style&gt;
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    &lt;/style&gt;
  &lt;progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
  0.00% [0/1 00:00&lt;00:00]
&lt;/div&gt;
</code></pre>
<!-- raw HTML omitted -->
<pre><code>&lt;div&gt;
    &lt;style&gt;
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    &lt;/style&gt;
  &lt;progress value='92' class='' max='506', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
  18.18% [92/506 00:21&lt;01:37 2.6318]
&lt;/div&gt;



LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
</code></pre>
<pre><code>learn.recorder.plot()
</code></pre><p><img src="200325_lesson3_planet_32_0.png" alt="png"></p>
<p>Then we can fit the head of our network.</p>
<pre><code>lr = 0.01
</code></pre><pre><code>learn.fit_one_cycle(5, slice(lr))
</code></pre><!-- raw HTML omitted -->
<pre><code>learn.save('stage-1-rn34')
</code></pre><p>&hellip;And fine-tune the whole model:</p>
<pre><code>learn.unfreeze()
</code></pre><pre><code>learn.lr_find()
learn.recorder.plot()
</code></pre><pre><code>&lt;div&gt;
    &lt;style&gt;
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    &lt;/style&gt;
  &lt;progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
  0.00% [0/1 00:00&lt;00:00]
&lt;/div&gt;
</code></pre>
<!-- raw HTML omitted -->
<pre><code>&lt;div&gt;
    &lt;style&gt;
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    &lt;/style&gt;
  &lt;progress value='85' class='' max='506', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
  16.80% [85/506 00:20&lt;01:42 0.2839]
&lt;/div&gt;



LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
</code></pre>
<p><img src="200325_lesson3_planet_39_2.png" alt="png"></p>
<pre><code>learn.fit_one_cycle(5, slice(1e-5, lr/5))
</code></pre><!-- raw HTML omitted -->
<pre><code>learn.save('stage-2-rn34')
</code></pre><pre><code>data = (src.transform(tfms, size=256)
        .databunch().normalize(imagenet_stats))

learn.data = data
data.train_ds[0][0].shape
</code></pre><pre><code>torch.Size([3, 256, 256])
</code></pre>
<pre><code>learn.freeze()
</code></pre><pre><code>learn.lr_find()
learn.recorder.plot()
</code></pre><pre><code>LR Finder complete, type {learner_name}.recorder.plot() to see the graph.
</code></pre>
<p><img src="200325_lesson3_planet_44_1.png" alt="png"></p>
<pre><code>lr=1e-2/2
</code></pre><pre><code>learn.fit_one_cycle(5, slice(lr))
</code></pre><p>Total time: 09:01 <!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<pre><code>learn.save('stage-1-256-rn50')
</code></pre><pre><code>learn.unfreeze()
</code></pre><pre><code>learn.fit_one_cycle(5, slice(1e-5, lr/5))
</code></pre><p>Total time: 11:25 <!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<pre><code>learn.recorder.plot_losses()
</code></pre><p><img src="200325_lesson3_planet_50_0.png" alt="png"></p>
<pre><code>learn.save('stage-2-256-rn50')
</code></pre><p>You won&rsquo;t really know how you&rsquo;re going until you submit to Kaggle, since the leaderboard isn&rsquo;t using the same subset as we have for training. But as a guide, 50th place (out of 938 teams) on the private leaderboard was a score of <code>0.930</code>.</p>
<pre><code>learn.export()
</code></pre><h2 id="fin">fin</h2>
<p>(This section will be covered in part 2 - please don&rsquo;t ask about it just yet! :) )</p>
<pre><code>#! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg.tar.7z -p {path}  
#! 7za -bd -y -so x {path}/test-jpg.tar.7z | tar xf - -C {path}
#! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg-additional.tar.7z -p {path}  
#! 7za -bd -y -so x {path}/test-jpg-additional.tar.7z | tar xf - -C {path}
</code></pre><pre><code>test = ImageList.from_folder(path/'test-jpg').add(ImageList.from_folder(path/'test-jpg-additional'))
len(test)
</code></pre><pre><code>61191
</code></pre>
<pre><code>learn = load_learner(path, test=test)
preds, _ = learn.get_preds(ds_type=DatasetType.Test)
</code></pre><pre><code>thresh = 0.2
labelled_preds = [' '.join([learn.data.classes[i] for i,p in enumerate(pred) if p &gt; thresh]) for pred in preds]
</code></pre><pre><code>labelled_preds[:5]
</code></pre><pre><code>['agriculture cultivation partly_cloudy primary road',
 'clear haze primary water',
 'agriculture clear cultivation primary',
 'clear primary',
 'partly_cloudy primary']
</code></pre>
<pre><code>fnames = [f.name[:-4] for f in learn.data.test_ds.items]
</code></pre><pre><code>df = pd.DataFrame({'image_name':fnames, 'tags':labelled_preds}, columns=['image_name', 'tags'])
</code></pre><pre><code>df.to_csv(path/'submission.csv', index=False)
</code></pre><pre><code>! kaggle competitions submit planet-understanding-the-amazon-from-space -f {path/'submission.csv'} -m &quot;My submission&quot;
</code></pre><pre><code>Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ubuntu/.kaggle/kaggle.json'
100%|██████████████████████████████████████| 2.18M/2.18M [00:02&lt;00:00, 1.05MB/s]
Successfully submitted to Planet: Understanding the Amazon from Space
</code></pre>
<p>Private Leaderboard score: 0.9296 (around 80th)</p><ul class="pa0">
  
</ul>
<div class="mt6">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hsv-ai" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://hsv-ai.com" >
    &copy; 2020 Huntsville AI
  </a>
    <div>


<a href="https://www.facebook.com/groups/390465874745286/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





<a href="https://www.linkedin.com/groups/12177562/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/HSV-AI" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
  </div>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-139852367-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
