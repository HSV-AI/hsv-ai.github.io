<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Huntsville AI  | Classification with Scikit-Learn</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.78.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Classification with Scikit-Learn" />
<meta property="og:description" content="This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.
The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: Musk (Version 2) Data Set" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hsv-ai.com/meetups/190213_musk_classification/" />
<meta property="article:published_time" content="2019-02-23T22:40:19-05:00" />
<meta property="article:modified_time" content="2019-02-23T22:40:19-05:00" />
<meta itemprop="name" content="Classification with Scikit-Learn">
<meta itemprop="description" content="This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.
The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: Musk (Version 2) Data Set">
<meta itemprop="datePublished" content="2019-02-23T22:40:19-05:00" />
<meta itemprop="dateModified" content="2019-02-23T22:40:19-05:00" />
<meta itemprop="wordCount" content="1487">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Classification with Scikit-Learn"/>
<meta name="twitter:description" content="This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.
The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: Musk (Version 2) Data Set"/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      

<nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://hsv-ai.com" class="f3 fw2 hover-white no-underline white-90 dib">
	<img src="https://hsv-ai.com/images/HSVAI_LOGOART_v5.png" style="height:50px;"></img>
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/meetups/" title="Meetups page">
              Meetups
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/neurips/" title="NeurIPS page">
              NeurIPS
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/projects/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      


<a href="https://www.facebook.com/groups/390465874745286/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





<a href="https://www.linkedin.com/groups/12177562/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/HSV-AI" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        MEETUPS
      </p>
      <h1 class="f1 athelas mb1">Classification with Scikit-Learn</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2019-02-23T22:40:19-05:00">February 23, 2019</time>      
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.</p>
<p>The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: <!-- raw HTML omitted -->Musk (Version 2) Data Set<!-- raw HTML omitted --></p>
<h3 id="data-set-information">Data Set Information:</h3>
<p>This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks. The goal is to learn to predict whether new molecules will be musks or non-musks. However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule. Because bonds can rotate, a single molecule can adopt many different shapes. To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations. Then, a feature vector was extracted that describes each conformation.</p>
<p>This many-to-one relationship between feature vectors and molecules is called the &ldquo;multiple instance problem&rdquo;. When learning a classifier for this data, the classifier should classify a molecule as &ldquo;musk&rdquo; if ANY of its conformations is classified as a musk. A molecule should be classified as &ldquo;non-musk&rdquo; if NONE of its conformations is classified as a musk.</p>
<h2 id="notebooks">Notebooks</h2>
<p>View the IPython notebook for this session on Github [here](<a href="https://github.com/HSV-AI/presentations/blob/master/2019/190213/MUSK">https://github.com/HSV-AI/presentations/blob/master/2019/190213/MUSK</a> Classification.ipynb)</p>
<p>Or launch the notebook in Google Colab or MyBinder:</p>
<p>[<img src="https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=terminal" alt="Google Colab">](<a href="https://colab.research.google.com/github/HSV-AI/presentations/blob/master/2019/190213/MUSK">https://colab.research.google.com/github/HSV-AI/presentations/blob/master/2019/190213/MUSK</a> Classification.ipynb)</p>
<p>[<img src="https://mybinder.org/badge_logo.svg" alt="Binder">](<a href="https://mybinder.org/v2/gh/HSV-AI/presentations/master?filepath=2019/190213/MUSK">https://mybinder.org/v2/gh/HSV-AI/presentations/master?filepath=2019/190213/MUSK</a> Classification.ipynb)</p>
<h2 id="loading-data">Loading data</h2>
<p>First we will load this data from the csv file into a Pandas dataframe and get a look at it.</p>
<p>You can see that by using a 0 based index, the features are in columns 3-168 and the class is in column 169.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics

df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;data/musk_csv.csv&#34;</span>) 
<span style="color:#75715e"># Preview the first 5 lines of the loaded data </span>
df<span style="color:#f92672">.</span>head()
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Total number of rows: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> len(df))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Breakdown by class:&#34;</span>)
<span style="color:#66d9ef">print</span>(df<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;class&#39;</span>)<span style="color:#f92672">.</span>size())
</code></pre></div><h2 id="training--validation">Training &amp; Validation</h2>
<p>Before we start looking at different methods for classification, we need to split this data into a training set and a validation set. The problem is that if we train using all of the data, we do not have an independent way of testing the accuracy of the model.</p>
<p>Luckily, scikit-learn provides an easy way to do this: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split</a></p>
<p>First, we will slice the original dataframe to create a dataframe with only the 166 attributes, and another with only the classes.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split

X <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>iloc[:,<span style="color:#ae81ff">3</span>:<span style="color:#ae81ff">169</span>]
y <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>iloc[:, <span style="color:#ae81ff">169</span>]
Xtrain, Xtest, ytrain, ytest <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=.</span><span style="color:#ae81ff">25</span>)

chance <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span> <span style="color:#f92672">**</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Chance of hittings heads ten times in a row: &#34;</span> <span style="color:#f92672">+</span> str(chance))
<span style="color:#66d9ef">print</span>(y<span style="color:#f92672">.</span>mean())
<span style="color:#66d9ef">print</span>(ytrain<span style="color:#f92672">.</span>mean())


</code></pre></div><h2 id="classifier-testing-approach">Classifier Testing Approach</h2>
<p>Now that we have the data ready for training and validation, we can start working through the different classifiers provided by scikit-learn. To do that, we will look at two primary measurements of each classifier:</p>
<ol>
<li>Accuracy - what percentage of the overal set did the model classify correctly</li>
<li>Confusion Matrix - which classes were classified correctly, and which were classified as the opposite</li>
</ol>
<p>Here is a great write-up for a <a href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">Confusion Matrix</a></p>
<p>A good place to start for finding a list of classifiers is <a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html">here</a></p>
<h2 id="support-vector-machine">Support Vector Machine</h2>
<p>The first classifier that we will look at is the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">Support Vector Classifier</a></p>
<p>This can be used with several different kernel types. We will start with the default &lsquo;rbf&rsquo;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> SVC  <span style="color:#75715e"># &#34;Support Vector Classifier&#34;</span>
clf <span style="color:#f92672">=</span> SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rbf&#39;</span>, gamma<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scale&#39;</span>)
clf<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);

</code></pre></div><h2 id="support-vector-machine-1">Support Vector Machine</h2>
<p>Next we will try the linear classifier. Note - this takes a long time&hellip;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># from sklearn.svm import SVC  # &#34;Support Vector Classifier&#34;</span>
<span style="color:#75715e"># clf = SVC(kernel=&#39;linear&#39;, gamma=&#39;scale&#39;)</span>
<span style="color:#75715e"># %time clf.fit(Xtrain, ytrain)</span>
<span style="color:#75715e"># ypred = clf.predict(Xtest)</span>
<span style="color:#75715e"># print(&#34;Accuracy: %f\n&#34; % metrics.accuracy_score(ypred, ytest))</span>

<span style="color:#75715e"># confusion_matrix = metrics.confusion_matrix(ypred, ytest)</span>
<span style="color:#75715e"># print(&#34;Confusion Matrix: &#34;)</span>
<span style="color:#75715e"># print(confusion_matrix)</span>
<span style="color:#75715e"># print()</span>

<span style="color:#75715e"># plt.imshow(confusion_matrix,</span>
<span style="color:#75715e">#            interpolation=&#39;nearest&#39;, cmap=plt.cm.binary)</span>
<span style="color:#75715e"># plt.grid(False)</span>
<span style="color:#75715e"># plt.colorbar()</span>
<span style="color:#75715e"># plt.xlabel(&#34;predicted label&#34;)</span>
<span style="color:#75715e"># plt.ylabel(&#34;true label&#34;);</span>

</code></pre></div><pre><code>CPU times: user 2h 15min 33s, sys: 97.1 ms, total: 2h 15min 34s
Wall time: 2h 15min 33s
Accuracy: 0.949697

Confusion Matrix: 
[[1366   54]
 [  29  201]]
</code></pre>
<p><img src="MUSK%20Classification_files/MUSK%20Classification_9_1.png" alt="png"></p>
<h2 id="decision-tree-classifier">Decision Tree Classifier</h2>
<p>The next classifier that we will look at is the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">Decision Tree Classifier</a>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
dtc <span style="color:#f92672">=</span> DecisionTreeClassifier()
dtc<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> dtc<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);

</code></pre></div><h2 id="random-forest-classifier">Random Forest Classifier</h2>
<p>The next classifier that we will look at is the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Random Forest Classifier</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
rfc <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
rfc<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> rfc<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);
</code></pre></div><h2 id="adaboost-classifier">AdaBoost Classifier</h2>
<p>How about an <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier">AdaBoost Classifier</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> AdaBoostClassifier
abc <span style="color:#f92672">=</span> AdaBoostClassifier(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
abc<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> abc<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);
</code></pre></div><h2 id="gaussian-naive-bayes">Gaussian Naive Bayes</h2>
<p>Did someone say &ldquo;<a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB">Gaussian Naive Bays</a>&rdquo;?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.naive_bayes <span style="color:#f92672">import</span> GaussianNB
gnb <span style="color:#f92672">=</span> GaussianNB()
gnb<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> gnb<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);
</code></pre></div><h2 id="quadraticdiscriminantanalysis">QuadraticDiscriminantAnalysis</h2>
<p>Everyone&rsquo;s favorite - <a href="https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis">QuadraticDiscriminantAnalysis</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.discriminant_analysis <span style="color:#f92672">import</span> QuadraticDiscriminantAnalysis
qda <span style="color:#f92672">=</span> QuadraticDiscriminantAnalysis()
qda<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> qda<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);
</code></pre></div><h2 id="k-nearest-neighbors">K-Nearest Neighbors</h2>
<p>Will you be my <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier">KNeighborsClassifier</a>?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.neighbors <span style="color:#f92672">import</span> KNeighborsClassifier
knc <span style="color:#f92672">=</span> KNeighborsClassifier()
knc<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> knc<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);
</code></pre></div><h2 id="multi-layer-perceptron-classifier">Multi-Layer Perceptron Classifier</h2>
<p>We can&rsquo;t have AI without <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier">MLPClassifier</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.neural_network <span style="color:#f92672">import</span> MLPClassifier
mlp <span style="color:#f92672">=</span> MLPClassifier()
mlp<span style="color:#f92672">.</span>fit(Xtrain, ytrain)
ypred <span style="color:#f92672">=</span> mlp<span style="color:#f92672">.</span>predict(Xtest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);
</code></pre></div><h2 id="dimensionality-reduction">Dimensionality Reduction</h2>
<p>Do we really need 166 attributes to be able to classify molecules as MUSK / NON-MUSK?</p>
<p>Are any of these attributes dependent on others?</p>
<p>We can use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">Primary Component Analysis</a> to give us a bit more information. First let&rsquo;s look at the explained variance ratio of the attributes (components) across the entire dataframe.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.decomposition <span style="color:#f92672">import</span> PCA

pca <span style="color:#f92672">=</span> PCA()<span style="color:#f92672">.</span>fit(X)
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>cumsum(pca<span style="color:#f92672">.</span>explained_variance_ratio_))
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;number of components&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;cumulative explained variance&#39;</span>);
</code></pre></div><p>We can also use PCA to reduce the component count while keeping a percentage of the variance. The next step shows that 95% of the variance can be kept with only 35 components.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pca <span style="color:#f92672">=</span> PCA(<span style="color:#ae81ff">0.95</span>) <span style="color:#75715e"># keep 95% of variance</span>
Xtotal_xform <span style="color:#f92672">=</span> pca<span style="color:#f92672">.</span>fit_transform(X)
Xtrain_xform <span style="color:#f92672">=</span> pca<span style="color:#f92672">.</span>fit_transform(Xtrain)
Xtest_xform <span style="color:#f92672">=</span> pca<span style="color:#f92672">.</span>transform(Xtest)
<span style="color:#66d9ef">print</span>(X<span style="color:#f92672">.</span>shape)
<span style="color:#66d9ef">print</span>(Xtotal_xform<span style="color:#f92672">.</span>shape)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;95</span><span style="color:#e6db74">% o</span><span style="color:#e6db74">f the variance can be represented by &#34;</span><span style="color:#f92672">+</span> str((Xtrain_xform<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">/</span> X<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>)) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">% o</span><span style="color:#e6db74">f the original components count!&#34;</span>)
</code></pre></div><h2 id="classification-with-dimensionality-reduction">Classification with Dimensionality Reduction</h2>
<p>Now let&rsquo;s try repeating the classification exercise with the reduced dimensionality dataframe.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
dtc <span style="color:#f92672">=</span> DecisionTreeClassifier()
dtc<span style="color:#f92672">.</span>fit(Xtrain_xform, ytrain)
ypred <span style="color:#f92672">=</span> dtc<span style="color:#f92672">.</span>predict(Xtest_xform)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%f</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> metrics<span style="color:#f92672">.</span>accuracy_score(ypred, ytest))

confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(ypred, ytest)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Confusion Matrix: &#34;</span>)
<span style="color:#66d9ef">print</span>(confusion_matrix)
<span style="color:#66d9ef">print</span>()

plt<span style="color:#f92672">.</span>imshow(confusion_matrix,
           interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest&#39;</span>, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>binary)
plt<span style="color:#f92672">.</span>grid(False)
plt<span style="color:#f92672">.</span>colorbar()
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;predicted label&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;true label&#34;</span>);

</code></pre></div><h2 id="k-fold-validation">K-Fold Validation</h2>
<p>Initially, we have been splitting the data into a 75% training set and a 25% testing set by random sampling. This is commonly called &ldquo;Cross-validation&rdquo;.</p>
<p>From <a href="https://machinelearningmastery.com/k-fold-cross-validation/">Machine Learning Mastery</a>:
Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.</p>
<p>An additional approach is known as k-Fold Validation:
The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 2-fold cross-validation</span>
X1, X2, y1, y2 <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
X1<span style="color:#f92672">.</span>shape, X2<span style="color:#f92672">.</span>shape
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rbf&#39;</span>, gamma<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scale&#39;</span>)<span style="color:#f92672">.</span>fit(X2, y2)<span style="color:#f92672">.</span>score(X1, y1))
<span style="color:#66d9ef">print</span>(SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rbf&#39;</span>, gamma<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scale&#39;</span>)<span style="color:#f92672">.</span>fit(X1, y1)<span style="color:#f92672">.</span>score(X2, y2))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> cross_val_score
cv <span style="color:#f92672">=</span> cross_val_score(SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rbf&#39;</span>, gamma<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scale&#39;</span>), X, y, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
cv<span style="color:#f92672">.</span>mean()
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> learning_curve

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">plot_learning_curve</span>(estimator):
    train_sizes, train_scores, test_scores <span style="color:#f92672">=</span> learning_curve(estimator, X, y, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)

    <span style="color:#75715e"># train_scores = result[0]</span>
    <span style="color:#75715e"># valid_scores = result[1]</span>
    title <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Learning Curves (&#34;</span><span style="color:#f92672">+</span> type(estimator)<span style="color:#f92672">.</span>__name__ <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;)&#34;</span>
    plt<span style="color:#f92672">.</span>figure()
    plt<span style="color:#f92672">.</span>title(title)
    plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Training examples&#34;</span>)
    plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Score&#34;</span>)
    train_scores_mean <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(train_scores, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    train_scores_std <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>std(train_scores, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    test_scores_mean <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(test_scores, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    test_scores_std <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>std(test_scores, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    plt<span style="color:#f92672">.</span>grid()

    plt<span style="color:#f92672">.</span>fill_between(train_sizes, train_scores_mean <span style="color:#f92672">-</span> train_scores_std,
                     train_scores_mean <span style="color:#f92672">+</span> train_scores_std, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>,
                     color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;r&#34;</span>)
    plt<span style="color:#f92672">.</span>fill_between(train_sizes, test_scores_mean <span style="color:#f92672">-</span> test_scores_std,
                     test_scores_mean <span style="color:#f92672">+</span> test_scores_std, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;g&#34;</span>)
    plt<span style="color:#f92672">.</span>plot(train_sizes, train_scores_mean, <span style="color:#e6db74">&#39;o-&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;r&#34;</span>,
             label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Training score&#34;</span>)
    plt<span style="color:#f92672">.</span>plot(train_sizes, test_scores_mean, <span style="color:#e6db74">&#39;o-&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;g&#34;</span>,
             label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Cross-validation score&#34;</span>)
    plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;best&#34;</span>)
    plt<span style="color:#f92672">.</span>show()

plot_learning_curve(GaussianNB())
<span style="color:#75715e"># plot_learning_curve(SVC())</span>
plot_learning_curve(DecisionTreeClassifier())
plot_learning_curve(RandomForestClassifier(n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>))
plot_learning_curve(AdaBoostClassifier())
plot_learning_curve(QuadraticDiscriminantAnalysis())
<span style="color:#75715e"># plot_learning_curve(KNeighborsClassifier())</span>
</code></pre></div><ul class="pa0">
  
</ul>
<div class="mt6">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hsv-ai" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://hsv-ai.com" >
    &copy; 2020 Huntsville AI
  </a>
    <div>


<a href="https://www.facebook.com/groups/390465874745286/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





<a href="https://www.linkedin.com/groups/12177562/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/HSV-AI" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
  </div>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-139852367-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
