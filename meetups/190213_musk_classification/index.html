<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Huntsville AI  | Classification with Scikit-Learn</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.55.5" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Classification with Scikit-Learn" />
<meta property="og:description" content="This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.

The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: Musk (Version 2) Data Set" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hsv-ai.com/meetups/190213_musk_classification/" />
<meta property="article:published_time" content="2019-02-23T22:40:19-05:00"/>
<meta property="article:modified_time" content="2019-02-23T22:40:19-05:00"/>

<meta itemprop="name" content="Classification with Scikit-Learn">
<meta itemprop="description" content="This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.

The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: Musk (Version 2) Data Set">


<meta itemprop="datePublished" content="2019-02-23T22:40:19-05:00" />
<meta itemprop="dateModified" content="2019-02-23T22:40:19-05:00" />
<meta itemprop="wordCount" content="1485">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Classification with Scikit-Learn"/>
<meta name="twitter:description" content="This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.

The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: Musk (Version 2) Data Set"/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      

<nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://hsv-ai.com" class="f3 fw2 hover-white no-underline white-90 dib">
	<img src="https://hsv-ai.com/images/HSVAI_LOGOART_v5.png" style="height:50px;"></img>
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/meetups/" title="Meetups page">
              Meetups
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/neurips/" title="NeurIPS page">
              NeurIPS
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/projects/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      


<a href="https://www.facebook.com/groups/390465874745286/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





<a href="https://www.linkedin.com/groups/12177562/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/HSV-AI" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        MEETUPS
      </p>
      <h1 class="f1 athelas mb1">Classification with Scikit-Learn</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2019-02-23T22:40:19-05:00">February 23, 2019</time>      
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.</p>

<p>The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: <a href="https://archive.ics.uci.edu/ml/datasets/Musk+(Version+2)">Musk (Version 2) Data Set</a></p>

<h3 id="data-set-information">Data Set Information:</h3>

<p>This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks. The goal is to learn to predict whether new molecules will be musks or non-musks. However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule. Because bonds can rotate, a single molecule can adopt many different shapes. To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations. Then, a feature vector was extracted that describes each conformation.</p>

<p>This many-to-one relationship between feature vectors and molecules is called the &ldquo;multiple instance problem&rdquo;. When learning a classifier for this data, the classifier should classify a molecule as &ldquo;musk&rdquo; if ANY of its conformations is classified as a musk. A molecule should be classified as &ldquo;non-musk&rdquo; if NONE of its conformations is classified as a musk.</p>

<h2 id="notebooks">Notebooks</h2>

<p>View the IPython notebook for this session on Github <a href="https://github.com/HSV-AI/presentations/blob/master/2019/190213/MUSK Classification.ipynb">here</a></p>

<p>Or launch the notebook in Google Colab or MyBinder:</p>

<p><a href="https://colab.research.google.com/github/HSV-AI/presentations/blob/master/2019/190213/MUSK Classification.ipynb"><img src="https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=terminal" alt="Google Colab" /></a></p>

<p><a href="https://mybinder.org/v2/gh/HSV-AI/presentations/master?filepath=2019/190213/MUSK Classification.ipynb"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<h2 id="loading-data">Loading data</h2>

<p>First we will load this data from the csv file into a Pandas dataframe and get a look at it.</p>

<p>You can see that by using a 0 based index, the features are in columns 3-168 and the class is in column 169.</p>

<pre><code class="language-python">import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics

df = pd.read_csv(&quot;data/musk_csv.csv&quot;) 
# Preview the first 5 lines of the loaded data 
df.head()
</code></pre>

<pre><code class="language-python">print(&quot;Total number of rows: %d&quot; % len(df))
print(&quot;Breakdown by class:&quot;)
print(df.groupby('class').size())
</code></pre>

<h2 id="training-validation">Training &amp; Validation</h2>

<p>Before we start looking at different methods for classification, we need to split this data into a training set and a validation set. The problem is that if we train using all of the data, we do not have an independent way of testing the accuracy of the model.</p>

<p>Luckily, scikit-learn provides an easy way to do this: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split</a></p>

<p>First, we will slice the original dataframe to create a dataframe with only the 166 attributes, and another with only the classes.</p>

<pre><code class="language-python">from sklearn.model_selection import train_test_split

X = df.iloc[:,3:169]
y = df.iloc[:, 169]
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=.25)

chance = 0.5 ** 10 * 100
print(&quot;Chance of hittings heads ten times in a row: &quot; + str(chance))
print(y.mean())
print(ytrain.mean())


</code></pre>

<h2 id="classifier-testing-approach">Classifier Testing Approach</h2>

<p>Now that we have the data ready for training and validation, we can start working through the different classifiers provided by scikit-learn. To do that, we will look at two primary measurements of each classifier:
1. Accuracy - what percentage of the overal set did the model classify correctly
2. Confusion Matrix - which classes were classified correctly, and which were classified as the opposite</p>

<p>Here is a great write-up for a <a href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">Confusion Matrix</a></p>

<p>A good place to start for finding a list of classifiers is <a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html">here</a></p>

<h2 id="support-vector-machine">Support Vector Machine</h2>

<p>The first classifier that we will look at is the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">Support Vector Classifier</a></p>

<p>This can be used with several different kernel types. We will start with the default &lsquo;rbf&rsquo;</p>

<pre><code class="language-python">from sklearn.svm import SVC  # &quot;Support Vector Classifier&quot;
clf = SVC(kernel='rbf', gamma='scale')
clf.fit(Xtrain, ytrain)
ypred = clf.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);

</code></pre>

<h2 id="support-vector-machine-1">Support Vector Machine</h2>

<p>Next we will try the linear classifier. Note - this takes a long time&hellip;</p>

<pre><code class="language-python"># from sklearn.svm import SVC  # &quot;Support Vector Classifier&quot;
# clf = SVC(kernel='linear', gamma='scale')
# %time clf.fit(Xtrain, ytrain)
# ypred = clf.predict(Xtest)
# print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

# confusion_matrix = metrics.confusion_matrix(ypred, ytest)
# print(&quot;Confusion Matrix: &quot;)
# print(confusion_matrix)
# print()

# plt.imshow(confusion_matrix,
#            interpolation='nearest', cmap=plt.cm.binary)
# plt.grid(False)
# plt.colorbar()
# plt.xlabel(&quot;predicted label&quot;)
# plt.ylabel(&quot;true label&quot;);

</code></pre>

<pre><code>CPU times: user 2h 15min 33s, sys: 97.1 ms, total: 2h 15min 34s
Wall time: 2h 15min 33s
Accuracy: 0.949697

Confusion Matrix: 
[[1366   54]
 [  29  201]]
</code></pre>

<p><img src="MUSK%20Classification_files/MUSK%20Classification_9_1.png" alt="png" /></p>

<h2 id="decision-tree-classifier">Decision Tree Classifier</h2>

<p>The next classifier that we will look at is the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">Decision Tree Classifier</a>.</p>

<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(Xtrain, ytrain)
ypred = dtc.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);

</code></pre>

<h2 id="random-forest-classifier">Random Forest Classifier</h2>

<p>The next classifier that we will look at is the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Random Forest Classifier</a></p>

<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=100, random_state=0)
rfc.fit(Xtrain, ytrain)
ypred = rfc.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);
</code></pre>

<h2 id="adaboost-classifier">AdaBoost Classifier</h2>

<p>How about an <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier">AdaBoost Classifier</a></p>

<pre><code class="language-python">from sklearn.ensemble import AdaBoostClassifier
abc = AdaBoostClassifier(random_state=0)
abc.fit(Xtrain, ytrain)
ypred = abc.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);
</code></pre>

<h2 id="gaussian-naive-bayes">Gaussian Naive Bayes</h2>

<p>Did someone say &ldquo;<a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB">Gaussian Naive Bays</a>&rdquo;?</p>

<pre><code class="language-python">from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(Xtrain, ytrain)
ypred = gnb.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);
</code></pre>

<h2 id="quadraticdiscriminantanalysis">QuadraticDiscriminantAnalysis</h2>

<p>Everyone&rsquo;s favorite - <a href="https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis">QuadraticDiscriminantAnalysis</a></p>

<pre><code class="language-python">from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
qda = QuadraticDiscriminantAnalysis()
qda.fit(Xtrain, ytrain)
ypred = qda.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);
</code></pre>

<h2 id="k-nearest-neighbors">K-Nearest Neighbors</h2>

<p>Will you be my <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier">KNeighborsClassifier</a>?</p>

<pre><code class="language-python">from sklearn.neighbors import KNeighborsClassifier
knc = KNeighborsClassifier()
knc.fit(Xtrain, ytrain)
ypred = knc.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);
</code></pre>

<h2 id="multi-layer-perceptron-classifier">Multi-Layer Perceptron Classifier</h2>

<p>We can&rsquo;t have AI without <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier">MLPClassifier</a></p>

<pre><code class="language-python">from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier()
mlp.fit(Xtrain, ytrain)
ypred = mlp.predict(Xtest)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);
</code></pre>

<h2 id="dimensionality-reduction">Dimensionality Reduction</h2>

<p>Do we really need 166 attributes to be able to classify molecules as MUSK / NON-MUSK?</p>

<p>Are any of these attributes dependent on others?</p>

<p>We can use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">Primary Component Analysis</a> to give us a bit more information. First let&rsquo;s look at the explained variance ratio of the attributes (components) across the entire dataframe.</p>

<pre><code class="language-python">from sklearn.decomposition import PCA

pca = PCA().fit(X)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
</code></pre>

<p>We can also use PCA to reduce the component count while keeping a percentage of the variance. The next step shows that 95% of the variance can be kept with only 35 components.</p>

<pre><code class="language-python">pca = PCA(0.95) # keep 95% of variance
Xtotal_xform = pca.fit_transform(X)
Xtrain_xform = pca.fit_transform(Xtrain)
Xtest_xform = pca.transform(Xtest)
print(X.shape)
print(Xtotal_xform.shape)
print(&quot;95% of the variance can be represented by &quot;+ str((Xtrain_xform.shape[1] / X.shape[1] * 100)) + &quot;% of the original components count!&quot;)
</code></pre>

<h2 id="classification-with-dimensionality-reduction">Classification with Dimensionality Reduction</h2>

<p>Now let&rsquo;s try repeating the classification exercise with the reduced dimensionality dataframe.</p>

<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(Xtrain_xform, ytrain)
ypred = dtc.predict(Xtest_xform)
print(&quot;Accuracy: %f\n&quot; % metrics.accuracy_score(ypred, ytest))

confusion_matrix = metrics.confusion_matrix(ypred, ytest)
print(&quot;Confusion Matrix: &quot;)
print(confusion_matrix)
print()

plt.imshow(confusion_matrix,
           interpolation='nearest', cmap=plt.cm.binary)
plt.grid(False)
plt.colorbar()
plt.xlabel(&quot;predicted label&quot;)
plt.ylabel(&quot;true label&quot;);

</code></pre>

<h2 id="k-fold-validation">K-Fold Validation</h2>

<p>Initially, we have been splitting the data into a 75% training set and a 25% testing set by random sampling. This is commonly called &ldquo;Cross-validation&rdquo;.</p>

<p>From <a href="https://machinelearningmastery.com/k-fold-cross-validation/">Machine Learning Mastery</a>:
Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.</p>

<p>An additional approach is known as k-Fold Validation:
The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.</p>

<pre><code class="language-python"># 2-fold cross-validation
X1, X2, y1, y2 = train_test_split(X, y, test_size=0.5, random_state=0)
X1.shape, X2.shape
</code></pre>

<pre><code class="language-python">print(SVC(kernel='rbf', gamma='scale').fit(X2, y2).score(X1, y1))
print(SVC(kernel='rbf', gamma='scale').fit(X1, y1).score(X2, y2))
</code></pre>

<pre><code class="language-python">from sklearn.model_selection import cross_val_score
cv = cross_val_score(SVC(kernel='rbf', gamma='scale'), X, y, cv=2)
cv.mean()
</code></pre>

<pre><code class="language-python">from sklearn.model_selection import learning_curve

def plot_learning_curve(estimator):
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=5)

    # train_scores = result[0]
    # valid_scores = result[1]
    title = &quot;Learning Curves (&quot;+ type(estimator).__name__ + &quot;)&quot;
    plt.figure()
    plt.title(title)
    plt.xlabel(&quot;Training examples&quot;)
    plt.ylabel(&quot;Score&quot;)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color=&quot;r&quot;)
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color=&quot;g&quot;)
    plt.plot(train_sizes, train_scores_mean, 'o-', color=&quot;r&quot;,
             label=&quot;Training score&quot;)
    plt.plot(train_sizes, test_scores_mean, 'o-', color=&quot;g&quot;,
             label=&quot;Cross-validation score&quot;)
    plt.legend(loc=&quot;best&quot;)
    plt.show()

plot_learning_curve(GaussianNB())
# plot_learning_curve(SVC())
plot_learning_curve(DecisionTreeClassifier())
plot_learning_curve(RandomForestClassifier(n_estimators=100))
plot_learning_curve(AdaBoostClassifier())
plot_learning_curve(QuadraticDiscriminantAnalysis())
# plot_learning_curve(KNeighborsClassifier())
</code></pre><ul class="pa0">
  
</ul>
<div class="mt6">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hsv-ai" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://hsv-ai.com" >
    &copy; 2020 Huntsville AI
  </a>
    <div>


<a href="https://www.facebook.com/groups/390465874745286/" target="_blank" class="link-transition facebook link dib z-999 pt3 pt0-l mr1" title="Facebook link" rel="noopener" aria-label="follow on Facebook——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





<a href="https://www.linkedin.com/groups/12177562/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/HSV-AI" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
  </div>
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-139852367-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
